Python을 사용하니까 그 기초를 좀 보자
    컴퓨터의 CPU, RAM, SSD를 활용하기 위해서
        1. 변수선언 : RAM 사용 문법 - 식별자(저장공간을 구분하는 문자열) - PEP20, PEP8(autopep8, flake)
        2. 데이터타입 : RAM 효율적 사용 문법 - int, float, bool, str, list, tuple, dict, set
        3. 연산자 : CPU 사용 문법 : 산술, 비교, 논리, 할당, 멤버 ...
        4. 조건문, 반복문 : if, elif, while, for, break, continue, range() ...
        5. 함수 : 반복 사용되는 코드를 묶어서 코드 작성 실행 : def, return, scope(global), lambda ...
        6. 클래스 : 변수, 함수를 묶어서 코드 작성 실행 - 객체지항 구현 - class, self, special methods(생성자)
        7. 모듈 : 변수, 함수, 클래스를 파일로 묶어서 코드 작성 실행 : 확장자 .py
        8. 패키지 : 여러개의 모듈을 디렉토리로 묶어서 관리: 버전정보 - import, from, as
        9. 입출력 : SSD 사용 문법 - RAM(object) > SSD(file), SSD(file) > RAM(object) - pickle
    
    class
        변수, 함수를 묶어서 코드 작성 실행
        객체지향 구현 : 실제세계를 모델링하여 프로그램을 개발하는 개발 방법론 : 헙업 용이
        함수 사용 : 함수 선언(코드 작성) > 함수 호출(코드 실행)
        클래스 사용
            클래스 선언(코드 작성-설계도 작성) > 객체 생성(메모리 사용-제품 생산) > 메서드 실행(코드 실행-제품 사용)
            메서드 : 클래스 안에 선언되는 함수
        class 식별자 : UpperCamelCase, PascalCase(O), snake_case(X:변수, 함수)


웹 크롤링
    웹 페이지에서 데이터를 수집하는 방법에 대해서 학습

    웹 페이지의 종류
        정적인 페이지 : 화면이 한번 뜨면 이벤트에 의한 화면 변경이 없음
        동적인 페이지 : 화면이 뜨고 이벤트가 발생하면 서버에서 데이터를 가져와 화면을 변경

    requests 이용 - 받아오는 문자열에 따라 2가지 방법으로 구분
        json 문자열로 받아서 파싱 : 주로 동적 페이지 크롤링할 때 사용
        html 문자열로 받아서 파싱 : 주로 정적 페이지 크롤링할 때 사용
    
    selenium 이용 - 브라우저를 직접 열어서 데이터를 받는 방법

    EX) 네이버 주식 데이터를 크롤링 해보자
        절차 : 웹 서비스 분석 - url : chrom devtool
            >> 서버에 데이터 요청 : request(url) - response : json(str)
            >> 서버에서 받은 데이터 파싱(형태 변경) - json(str) - list, dict - DataFrame
        
        